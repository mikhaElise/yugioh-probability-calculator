# -*- coding: utf-8 -*-
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import math
from PIL import Image
import altair as alt  # æ–°å¢: å¯¼å…¥ Altair å›¾è¡¨åº“

# --- é¡µé¢é…ç½® (åŒ…å«ä¸»é¢˜è®¾ç½®) ---
st.set_page_config(
    layout="wide",
    page_title="YGO Prob Calc",
    page_icon="ğŸ²",
    initial_sidebar_state="auto" # è®©ä¾§è¾¹æ çŠ¶æ€æ›´ç¨³å®š
)
# --- é¡µé¢é…ç½®ç»“æŸ ---

@st.cache_data
def safe_comb(n, k):
    if k < 0 or n < k or n < 0:
        return 0
    try:
        return math.comb(n, k)
    except ValueError:
        return 0

@st.cache_data
def calculate_single_prob(K, N, n):
    if n == 0:
        return 0.0
    if K < 0:
        K = 0
    if K > N:
        K = N
        
    total_combinations = safe_comb(N, n)
    if total_combinations == 0:
        return 0.0

    num_non_starters = N - K
    ways_to_draw_zero_starters = safe_comb(num_non_starters, n)
        
    prob_zero_starters = ways_to_draw_zero_starters / total_combinations
    return 1.0 - prob_zero_starters

@st.cache_data
def calculate_exact_prob(i, K, N, n):
    if n == 0:
        return 0.0
    if K < i:
        return 0.0
    
    total_combinations = safe_comb(N, n)
    if total_combinations == 0:
        return 0.0
    
    non_starters = N - K
    draw_non_starters = n - i
    if draw_non_starters < 0:
        return 0.0
    
    ways_to_draw_exact = safe_comb(K, i) * safe_comb(non_starters, draw_non_starters)
    
    return ways_to_draw_exact / total_combinations

@st.cache_data
def get_starter_probability_data(N, n):
    
    plot_k_col = list(range(N + 1))
    
    P_exact_full = [[calculate_exact_prob(i, k, N, n) for k in range(-1, N + 2)] for i in range(n + 1)]
    P_cumulative_full = [[0.0] * (N + 3) for _ in range(n + 1)]

    for k_idx in range(N + 3):
        p_sum = 0.0
        for i in range(n, -1, -1):
             p_sum += P_exact_full[i][k_idx]
             P_cumulative_full[i][k_idx] = p_sum

    df_plot = pd.DataFrame({"K (Starters)": plot_k_col})
    df_plot["P(X >= 1)"] = P_cumulative_full[1][1 : N + 2]
    df_plot["P(X >= 2)"] = P_cumulative_full[2][1 : N + 2]
    df_plot["P(X >= 3)"] = P_cumulative_full[3][1 : N + 2]
    df_plot["P(X >= 4)"] = P_cumulative_full[4][1 : N + 2]
    df_plot["P(X = 5)"] = P_exact_full[5][1 : N + 2]
    df_plot = df_plot.set_index("K (Starters)")

    all_tables = []
    curve_names = [
        "P(X >= 1) / è‡³å°‘1å¼ åŠ¨ç‚¹",
        "P(X >= 2) / è‡³å°‘2å¼ åŠ¨ç‚¹",
        "P(X >= 3) / è‡³å°‘3å¼ åŠ¨ç‚¹",
        "P(X >= 4) / è‡³å°‘4å¼ åŠ¨ç‚¹",
        "P(X = 5) / æ­£å¥½5å¼ åŠ¨ç‚¹"
    ]
    
    data_sources = [
        P_cumulative_full[1],
        P_cumulative_full[2],
        P_cumulative_full[3],
        P_cumulative_full[4],
        P_exact_full[5]
    ]

    turning_points = {} # æ–°å¢: ç”¨äºå­˜å‚¨è½¬æŠ˜ç‚¹

    for i_curve in range(5):
        table_K_col = list(range(1, N + 1))
        P_curve = data_sources[i_curve]
        table_P_col = P_curve[2 : N + 2]
        table_D_col = [P_curve[k+2] - P_curve[k+1] for k in range(len(table_K_col))]
        table_C_col = [P_curve[k+3] - 2*P_curve[k+2] + P_curve[k+1] for k in range(len(table_K_col))]
        
        # æ–°å¢: è®¡ç®—è½¬æŠ˜ç‚¹
        if table_D_col:
            try:
                max_marginal_gain = max(table_D_col)
                # æ‰¾åˆ°æœ€å¤§è¾¹é™…æ”¶ç›Šå¯¹åº”çš„ç´¢å¼•
                turning_point_idx = table_D_col.index(max_marginal_gain)
                # å¯¹åº”çš„ K å€¼
                turning_point_k = table_K_col[turning_point_idx]
                curve_name = df_plot.columns[i_curve]
                turning_points[curve_name] = turning_point_k
            except (ValueError, IndexError):
                pass # å¦‚æœåˆ—è¡¨ä¸ºç©ºæˆ–æ‰¾ä¸åˆ°ï¼Œåˆ™å¿½ç•¥

        df_table = pd.DataFrame({
            "K (Starters / åŠ¨ç‚¹)": table_K_col,
            "Probability / æ¦‚ç‡": table_P_col,
            "Marginal / è¾¹é™…": table_D_col,
            "Curvature / æ›²ç‡": table_C_col
        }).set_index("K (Starters / åŠ¨ç‚¹)")
        
        df_display = df_table.copy()
        df_display["Probability / æ¦‚ç‡"] = df_display["Probability / æ¦‚ç‡"].map('{:.4%}'.format)
        df_display["Marginal / è¾¹é™…"] = df_display["Marginal / è¾¹é™…"].map('{:+.4%}'.format)
        df_display["Curvature / æ›²ç‡"] = df_display["Curvature / æ›²ç‡"].map('{:+.4%}'.format)
        
        all_tables.append((curve_names[i_curve], df_display))

    return df_plot, all_tables, turning_points # ä¿®æ”¹: è¿”å›è½¬æŠ˜ç‚¹

def calculate_combo_prob_single(A, D, n, K_fixed, total_comb, comb_not_K):
    if A < 0:
        return 0.0
    if total_comb == 0:
        return 0.0
    comb_not_A = safe_comb(D - A, n)
    comb_not_A_and_not_K = safe_comb(D - K_fixed - A, n)
    prob_A_is_0_or_K_is_0_num = (comb_not_A + comb_not_K - comb_not_A_and_not_K)
    prob_A_is_0_or_K_is_0 = prob_A_is_0_or_K_is_0_num / total_comb
    return 1.0 - prob_A_is_0_or_K_is_0

@st.cache_data
def get_combo_probability_data(D, n, K_fixed):
    max_A = D - K_fixed
    total_comb = safe_comb(D, n)
    comb_not_K = safe_comb(D - K_fixed, n)
    P_values_full = [calculate_combo_prob_single(a, D, n, K_fixed, total_comb, comb_not_K) for a in range(-1, max_A + 2)]

    plot_A_col = list(range(max_A + 1))
    plot_P_col = P_values_full[1 : max_A + 2]
    df_plot = pd.DataFrame({
        "A (Insecticides)": plot_A_col, 
        "Probability": plot_P_col     
    }).set_index("A (Insecticides)")

    table_A_col = list(range(max_A + 1))
    table_P_col = P_values_full[1 : max_A + 2]
    table_D_col = [P_values_full[i+2] - P_values_full[i+1] for i in range(len(table_A_col))]
    table_C_col = [P_values_full[i+2] - 2*P_values_full[i+1] + P_values_full[i] for i in range(len(table_A_col))]
    
    # æ–°å¢: è®¡ç®—è½¬æŠ˜ç‚¹
    turning_point = None
    if table_D_col:
        try:
            max_marginal_gain = max(table_D_col)
            turning_point_idx = table_D_col.index(max_marginal_gain)
            turning_point = table_A_col[turning_point_idx]
        except (ValueError, IndexError):
            turning_point = None # æ‰¾ä¸åˆ°åˆ™ä¸º None

    df_table = pd.DataFrame({
        "A (Insecticides / æ€è™«å‰‚)": table_A_col, 
        "Probability / æ¦‚ç‡": table_P_col,
        "P(A+1) - P(A) (Marginal / è¾¹é™…)": table_D_col,
        "P(A+1)-2P(A)+P(A-1) (Curvature / æ›²ç‡)": table_C_col
    }).set_index("A (Insecticides / æ€è™«å‰‚)")

    return df_plot, df_table, turning_point # ä¿®æ”¹: è¿”å›è½¬æŠ˜ç‚¹

@st.cache_data
def calculate_part3_prob_single(NE, D, K_fixed, i):
    """
    è®¡ç®—ï¼š5å¼ æ‰‹ç‰Œæœ‰iå¼ ç³»ç»Ÿå¤–ï¼Œ6å¼ ç‰Œä¸­è‡³å°‘1å¼ åŠ¨ç‚¹
    """
    n = 5
    if i < 0 or i > 5 or NE < 0 or K_fixed < 0 or D < n:
        return 0.0
    Trash = D - NE - K_fixed
    if Trash < 0:
        return 0.0
    total_comb_5 = safe_comb(D, n)
    if total_comb_5 == 0:
        return 0.0
    prob_case1 = 0.0
    for k in range(1, min(K_fixed, 5-i) + 1):
        if i + k <= 5:
            ways = (safe_comb(NE, i) * safe_comb(K_fixed, k) * safe_comb(Trash, 5-i-k))
            prob_case1 += ways / total_comb_5
    if 5-i >= 0 and Trash >= 5-i:
        ways_5cards = (safe_comb(NE, i) * safe_comb(K_fixed, 0) * safe_comb(Trash, 5-i))
        prob_5cards = ways_5cards / total_comb_5 if total_comb_5 > 0 else 0.0
        remaining_cards = D - 5
        remaining_K = K_fixed
        if remaining_cards > 0 and remaining_K > 0:
            prob_6th_K = remaining_K / remaining_cards
            prob_case2 = prob_5cards * prob_6th_K
        else:
            prob_case2 = 0.0
    else:
        prob_case2 = 0.0
    return prob_case1 + prob_case2

@st.cache_data
def calculate_part3_prob_single_case7(NE, D, K_fixed):
    """
    ç‰¹æ®Šæƒ…å†µï¼š5å¼ æ‰‹ç‰Œæœ‰5å¼ ç³»ç»Ÿå¤–ï¼Œ6å¼ ç‰Œä¸­0å¼ åŠ¨ç‚¹
    """
    n = 5
    if NE < 5 or K_fixed == 0: return 0.0
    Trash = D - NE - K_fixed
    if Trash < 0: return 0.0
    total_comb_5 = safe_comb(D, n)
    if total_comb_5 == 0: return 0.0
    ways_5cards = safe_comb(NE, 5) * safe_comb(K_fixed, 0) * safe_comb(Trash, 0)
    prob_5cards = ways_5cards / total_comb_5
    remaining_cards = D - 5
    remaining_K = K_fixed
    if remaining_cards > 0:
        prob_6th_not_K = (remaining_cards - remaining_K) / remaining_cards
    else:
        prob_6th_not_K = 1.0
    return prob_5cards * prob_6th_not_K

@st.cache_data
def get_part3_data(D, K_fixed):
    max_NE = D - K_fixed
    P_full = [[] for _ in range(8)]
    for ne_val in range(-1, max_NE + 2):
        for i in range(0, 6): P_full[i].append(calculate_part3_prob_single(ne_val, D, K_fixed, i))
        P_full[7].append(calculate_part3_prob_single_case7(ne_val, D, K_fixed))
    plot_NE_col = list(range(max_NE + 1))
    df_plot = pd.DataFrame({"NE (Non-Engine)": plot_NE_col}) 
    df_plot["C0 (i=0 NE)"] = P_full[0][1 : max_NE + 2] 
    df_plot["C1 (i=1 NE)"] = P_full[1][1 : max_NE + 2] 
    df_plot["C2 (i=2 NE)"] = P_full[2][1 : max_NE + 2] 
    df_plot["C3 (i=3 NE)"] = P_full[3][1 : max_NE + 2] 
    df_plot["C4 (i=4 NE)"] = P_full[4][1 : max_NE + 2] 
    df_plot["C6 (i=5 NE, >=1 K)"] = P_full[5][1 : max_NE + 2] 
    df_plot["C7 (i=5 NE, 0 K)"] = P_full[7][1 : max_NE + 2] 
    df_plot = df_plot.set_index("NE (Non-Engine)")
    all_tables = []
    curve_names = ["C0: P(0 NE in 5, >=1 K in 6) / æŠ½5å¼ å«0ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C1: P(1 NE in 5, >=1 K in 6) / æŠ½5å¼ å«1ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C2: P(2 NE in 5, >=1 K in 6) / æŠ½5å¼ å«2ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C3: P(3 NE in 5, >=1 K in 6) / æŠ½5å¼ å«3ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C4: P(4 NE in 5, >=1 K in 6) / æŠ½5å¼ å«4ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C6: P(5 NE in 5, >=1 K in 6) / æŠ½5å¼ å«5ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C7: P(5 NE in 5, 0 K in 6) / æŠ½5å¼ å«5ç³»ç»Ÿå¤–, æŠ½6å¼ å«0åŠ¨ç‚¹"]
    
    turning_points = {} # æ–°å¢
    
    internal_indices_map = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:7} # Map curve index to P_full index
    
    for i_curve in range(len(df_plot.columns)):
        i_curve_internal = internal_indices_map.get(i_curve, i_curve)
        table_NE_col = list(range(max_NE + 1))
        P_curve = P_full[i_curve_internal]
        table_P_col = P_curve[1 : max_NE + 2]
        table_D_col = [P_curve[j+2] - P_curve[j+1] for j in range(len(table_NE_col))]
        table_C_col = [P_curve[j+2] - 2*P_curve[j+1] + P_curve[j] for j in range(len(table_NE_col))]
        
        # æ–°å¢: è®¡ç®—è½¬æŠ˜ç‚¹
        if table_D_col:
            try:
                max_marginal_gain = max(table_D_col)
                turning_point_idx = table_D_col.index(max_marginal_gain)
                turning_point_ne = table_NE_col[turning_point_idx]
                curve_name = df_plot.columns[i_curve]
                turning_points[curve_name] = turning_point_ne
            except (ValueError, IndexError):
                pass

        df_table = pd.DataFrame({"NE (Non-Engine / ç³»ç»Ÿå¤–)": table_NE_col, "Probability / æ¦‚ç‡": table_P_col, "Marginal / è¾¹é™…": table_D_col, "Curvature / æ›²ç‡": table_C_col}).set_index("NE (Non-Engine / ç³»ç»Ÿå¤–)")
        df_display = df_table.copy()
        df_display["Probability / æ¦‚ç‡"] = df_display["Probability / æ¦‚ç‡"].map('{:.4%}'.format)
        df_display["Marginal / è¾¹é™…"] = df_display["Marginal / è¾¹é™…"].map('{:+.4%}'.format)
        df_display["Curvature / æ›²ç‡"] = df_display["Curvature / æ›²ç‡"].map('{:+.4%}'.format)
        table_name = curve_names[5] if i_curve_internal == 5 else (curve_names[6] if i_curve_internal == 7 else curve_names[i_curve_internal])
        all_tables.append((table_name, df_display))

    return df_plot, all_tables, turning_points # ä¿®æ”¹

@st.cache_data
def get_part3_cumulative_data(D, K_fixed):
    max_NE = D - K_fixed
    P_exact_full = [[calculate_part3_prob_single(ne_val, D, K_fixed, i) for ne_val in range(-1, max_NE + 2)] for i in range(6)] 
    P_cumulative_full = [[0.0] * (max_NE + 3) for _ in range(5)] 
    for ne_idx in range(max_NE + 3): 
        p_sum = sum(P_exact_full[i][ne_idx] for i in range(6))
        for i in range(5):
            P_cumulative_full[i][ne_idx] = sum(P_exact_full[j][ne_idx] for j in range(i + 1, 6))

    plot_NE_col = list(range(max_NE + 1))
    df_plot = pd.DataFrame({"NE (Non-Engine)": plot_NE_col}) 
    df_plot["C_ge1 (>=1 NE)"] = P_cumulative_full[0][1 : max_NE + 2] 
    df_plot["C_ge2 (>=2 NE)"] = P_cumulative_full[1][1 : max_NE + 2] 
    df_plot["C_ge3 (>=3 NE)"] = P_cumulative_full[2][1 : max_NE + 2] 
    df_plot["C_ge4 (>=4 NE)"] = P_cumulative_full[3][1 : max_NE + 2] 
    df_plot["C_ge5 (>=5 NE)"] = P_cumulative_full[4][1 : max_NE + 2] 
    df_plot = df_plot.set_index("NE (Non-Engine)")

    all_tables = []
    curve_names = ["C_ge1: P(>=1 NE in 5, >=1 K in 6) / æŠ½5å¼ å«>=1ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C_ge2: P(>=2 NE in 5, >=1 K in 6) / æŠ½5å¼ å«>=2ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C_ge3: P(>=3 NE in 5, >=1 K in 6) / æŠ½5å¼ å«>=3ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C_ge4: P(>=4 NE in 5, >=1 K in 6) / æŠ½5å¼ å«>=4ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹", "C_ge5: P(>=5 NE in 5, >=1 K in 6) / æŠ½5å¼ å«>=5ç³»ç»Ÿå¤–, æŠ½6å¼ å«>=1åŠ¨ç‚¹"]
    
    turning_points = {} # æ–°å¢

    for i_curve in range(5): 
        table_NE_col = list(range(max_NE + 1))
        P_curve = P_cumulative_full[i_curve] 
        table_P_col = P_curve[1 : max_NE + 2] 
        table_D_col = [P_curve[j+2] - P_curve[j+1] for j in range(len(table_NE_col))]
        table_C_col = [P_curve[j+2] - 2*P_curve[j+1] + P_curve[j] for j in range(len(table_NE_col))]
        
        # æ–°å¢
        if table_D_col:
            try:
                max_marginal_gain = max(table_D_col)
                turning_point_idx = table_D_col.index(max_marginal_gain)
                turning_point_ne = table_NE_col[turning_point_idx]
                curve_name = df_plot.columns[i_curve]
                turning_points[curve_name] = turning_point_ne
            except (ValueError, IndexError):
                pass
        
        df_table = pd.DataFrame({"NE (Non-Engine / ç³»ç»Ÿå¤–)": table_NE_col, "Probability / æ¦‚ç‡": table_P_col, "Marginal / è¾¹é™…": table_D_col, "Curvature / æ›²ç‡": table_C_col}).set_index("NE (Non-Engine / ç³»ç»Ÿå¤–)")
        df_display = df_table.copy()
        df_display["Probability / æ¦‚ç‡"] = df_display["Probability / æ¦‚ç‡"].map('{:.4%}'.format)
        df_display["Marginal / è¾¹é™…"] = df_display["Marginal / è¾¹é™…"].map('{:+.4%}'.format)
        df_display["Curvature / æ›²ç‡"] = df_display["Curvature / æ›²ç‡"].map('{:+.4%}'.format)
        all_tables.append((curve_names[i_curve], df_display))

    return df_plot, all_tables, turning_points # ä¿®æ”¹


@st.cache_data
def calculate_part4_prob_single(NE, D, K_fixed, i):
    n_draw = 6
    j = n_draw - i 
    if i < 0 or j < 0 or K_fixed < j or NE < i: return 0.0
    Trash = D - K_fixed - NE
    total_combinations = safe_comb(D, n_draw)
    if total_combinations == 0: return 0.0
    ways_to_draw_exact = safe_comb(NE, i) * safe_comb(K_fixed, j) * safe_comb(Trash, 0)
    return ways_to_draw_exact / total_combinations

@st.cache_data
def get_part4_data(D, K_fixed):
    max_NE = D - K_fixed
    P_full = [[] for _ in range(7)] 
    for ne_val in range(-1, max_NE + 2):
        for i in range(1, 7): P_full[i].append(calculate_part4_prob_single(ne_val, D, K_fixed, i))
    plot_NE_col = list(range(max_NE + 1))
    df_plot = pd.DataFrame({"NE (Non-Engine)": plot_NE_col}) 
    df_plot["C1 (1NE, 5K)"] = P_full[1][1 : max_NE + 2] 
    df_plot["C2 (2NE, 4K)"] = P_full[2][1 : max_NE + 2] 
    df_plot["C3 (3NE, 3K)"] = P_full[3][1 : max_NE + 2] 
    df_plot["C4 (4NE, 2K)"] = P_full[4][1 : max_NE + 2] 
    df_plot["C5 (5NE, 1K)"] = P_full[5][1 : max_NE + 2] 
    df_plot["C6 (6NE, 0K)"] = P_full[6][1 : max_NE + 2] 
    df_plot = df_plot.set_index("NE (Non-Engine)")
    all_tables = []
    curve_names = ["", "C1: P(1 NE, 5 K in 6) / æŠ½6å¼ å«1ç³»ç»Ÿå¤–, 5åŠ¨ç‚¹", "C2: P(2 NE, 4 K in 6) / æŠ½6å¼ å«2ç³»ç»Ÿå¤–, 4åŠ¨ç‚¹", "C3: P(3 NE, 3 K in 6) / æŠ½6å¼ å«3ç³»ç»Ÿå¤–, 3åŠ¨ç‚¹", "C4: P(4 NE, 2 K in 6) / æŠ½6å¼ å«4ç³»ç»Ÿå¤–, 2åŠ¨ç‚¹", "C5: P(5 NE, 1 K in 6) / æŠ½6å¼ å«5ç³»ç»Ÿå¤–, 1åŠ¨ç‚¹", "C6: P(6 NE, 0 K in 6) / æŠ½6å¼ å«6ç³»ç»Ÿå¤–, 0åŠ¨ç‚¹"]
    
    turning_points = {} # æ–°å¢

    for i_curve in range(1, 7): 
        table_NE_col = list(range(max_NE + 1))
        P_curve = P_full[i_curve] 
        table_P_col = P_curve[1 : max_NE + 2] 
        table_D_col = [P_curve[j+2] - P_curve[j+1] for j in range(len(table_NE_col))]
        table_C_col = [P_curve[j+2] - 2*P_curve[j+1] + P_curve[j] for j in range(len(table_NE_col))]
        
        # æ–°å¢
        if table_D_col:
            try:
                max_marginal_gain = max(table_D_col)
                turning_point_idx = table_D_col.index(max_marginal_gain)
                turning_point_ne = table_NE_col[turning_point_idx]
                curve_name = df_plot.columns[i_curve-1]
                turning_points[curve_name] = turning_point_ne
            except (ValueError, IndexError):
                pass
        
        df_table = pd.DataFrame({"NE (Non-Engine / ç³»ç»Ÿå¤–)": table_NE_col, "Probability / æ¦‚ç‡": table_P_col, "Marginal / è¾¹é™…": table_D_col, "Curvature / æ›²ç‡": table_C_col}).set_index("NE (Non-Engine / ç³»ç»Ÿå¤–)")
        df_display = df_table.copy()
        df_display["Probability / æ¦‚ç‡"] = df_display["Probability / æ¦‚ç‡"].map('{:.4%}'.format)
        df_display["Marginal / è¾¹é™…"] = df_display["Marginal / è¾¹é™…"].map('{:+.4%}'.format)
        df_display["Curvature / æ›²ç‡"] = df_display["Curvature / æ›²ç‡"].map('{:+.4%}'.format)
        all_tables.append((curve_names[i_curve], df_display))

    return df_plot, all_tables, turning_points # ä¿®æ”¹


# ===== GoatCounter & Google Analytics (No changes) =====
GOATCOUNTER_SCRIPT = """
<script data-goatcounter="https://mikhaelise.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
"""
if 'gc_injected' not in st.session_state:
    st.session_state.gc_injected = False
if not st.session_state.gc_injected:
    components.html(GOATCOUNTER_SCRIPT, height=0)
    st.session_state.gc_injected = True

GA_ID = "G-NKZ1V5K6B3"
if 'ga_injected' not in st.session_state:
    st.session_state.ga_injected = False
if not st.session_state.ga_injected:
    GA_SCRIPT = f"""
    <script async src="https://www.googletagmanager.com/gtag/js?id={GA_ID}"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){{dataLayer.push(arguments);}}
      gtag('js', new Date());
      gtag('config', '{GA_ID}', {{ 'page_title': 'YGO Probability Calculator', 'page_location': window.location.href }});
    </script>
    """
    components.html(GA_SCRIPT, height=0)
    st.session_state.ga_injected = True
# ===== End of Analytics scripts =====

# --- Sidebar (No changes) ---
try:
    img = Image.open("avatar.png") 
    target_width=150; w_percent=(target_width/float(img.size[0])); target_height=int((float(img.size[1])*float(w_percent)))
    img_resized = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    st.sidebar.image(img_resized)
except FileNotFoundError: st.sidebar.caption("avatar.png not found.")
except Exception as e: st.sidebar.error(f"Error loading image: {e}")

st.sidebar.markdown("Made by mikhaElise")
st.sidebar.markdown("Bilibili: https://b23.tv/9aM3G4T")
st.sidebar.header("Parameters / å‚æ•°")

DECK_SIZE = st.sidebar.number_input("1. Total Deck Size (D) / å¡ç»„æ€»æ•°", min_value=40, max_value=60, value=40, step=1, help="è®¾ç½®å¡ç»„æ€»æ•° (40-60)")
HAND_SIZE = st.sidebar.number_input("2. Opening Hand Size (n) / èµ·æ‰‹æ•°", min_value=0, max_value=10, value=5, step=1, help="è®¾ç½®èµ·æ‰‹æŠ½å‡ å¼ ç‰Œ (0-10)ã€‚æ³¨æ„: Part 3 & 4 è®¡ç®—å›ºå®šä¸ºèµ·æ‰‹5å¼ ï¼ŒæŠ½ç¬¬6å¼ ã€‚")
STARTER_COUNT_K = st.sidebar.number_input("3. Starter Size (K) / åŠ¨ç‚¹æ•°", min_value=0, max_value=DECK_SIZE, value=min(17, DECK_SIZE), step=1, help="ä¸º Part 2, 3 å’Œ 4 çš„è®¡ç®—è®¾ç½®å›ºå®šçš„åŠ¨ç‚¹ (K) æ•°é‡ã€‚")
K_HIGHLIGHT = st.sidebar.number_input("4. Highlight Starter Value (K) / é«˜äº®åŠ¨ç‚¹æ•° (ç”¨äº Part 1)", min_value=0, max_value=DECK_SIZE, value=min(17, DECK_SIZE), step=1, help=f"è¾“å…¥ä¸€ä¸ª K å€¼ (0 åˆ° {DECK_SIZE})ï¼Œå°†åœ¨ Part 1 å›¾è¡¨ä¸‹æ–¹æ˜¾ç¤ºè¯¥ç‚¹çš„ç²¾ç¡®æ¦‚ç‡ã€‚")

max_ne_possible = DECK_SIZE - STARTER_COUNT_K
max_ne_possible = max(0, max_ne_possible) 
NE_HIGHLIGHT = st.sidebar.number_input("5. Non-engine Sizeï¼ˆNEï¼‰/ç³»ç»Ÿå¤–æ•°é‡", min_value=0, max_value=max_ne_possible, value=min(20, max_ne_possible), step=1, help=f"è¾“å…¥ä¸€ä¸ª NE å€¼ (0 åˆ° {max_ne_possible})ï¼Œå°†åœ¨ Part 3 å’Œ 4 å›¾è¡¨ä¸‹æ–¹æ˜¾ç¤ºè¯¥ç‚¹çš„ç²¾ç¡®æ¦‚ç‡ã€‚")
# --- End of Sidebar ---

st.title("YGO Opening Hand Probability Calculator / YGOèµ·æ‰‹æ¦‚ç‡è®¡ç®—å™¨")
st.write(f"Current Settings / å½“å‰è®¾ç½®: **{DECK_SIZE}** Card Deck / å¡ç»„æ€»æ•°, **{HAND_SIZE}** Card Hand / èµ·æ‰‹å¡æ•°")
st.caption(f"Part 2, 3 & 4 Fixed Starter Count (K) / Part 2, 3 & 4 å›ºå®šåŠ¨ç‚¹æ•° = **{STARTER_COUNT_K}**")


# =================================================================================
# Part 1
# =================================================================================
st.header("Part 1: P(At least X Starter) / Part 1: èµ·æ‰‹è‡³å°‘Xå¼ åŠ¨ç‚¹æ¦‚ç‡")
st.write("This chart shows the probability of drawing specific numbers of 'Starter' cards (K) in your opening hand (n cards), as K (the X-axis) increases. / æ­¤å›¾è¡¨æ˜¾ç¤ºéšç€å¡ç»„ä¸­åŠ¨ç‚¹ (K) æ•°é‡ (Xè½´) çš„å¢åŠ ï¼Œèµ·æ‰‹æ‰‹ç‰Œ (nå¼ ) ä¸­æŠ½åˆ°ç‰¹å®šæ•°é‡åŠ¨ç‚¹çš„æ¦‚ç‡ã€‚")
st.subheader("Probability Formulas / æ¦‚ç‡å…¬å¼")
st.latex(r"P(X \geq x) = 1 - \sum_{i=0}^{x-1} \frac{\binom{K}{i} \binom{D-K}{n-i}}{\binom{D}{n}}")

df_plot_1, all_tables_1, turning_points_1 = get_starter_probability_data(DECK_SIZE, HAND_SIZE) 

# --- ä¿®æ”¹: ä½¿ç”¨ Altair ç»˜åˆ¶å›¾è¡¨ ---
df_plot_1_melted = df_plot_1.reset_index().melt('K (Starters)', var_name='Curve', value_name='Probability')
base_chart_1 = alt.Chart(df_plot_1_melted).encode(
    x=alt.X('K (Starters):Q', title='K (Number of Starters in Deck)'),
    y=alt.Y('Probability:Q', axis=alt.Axis(format='%'), title='Probability'),
    color='Curve:N',
    tooltip=['K (Starters)', 'Curve', alt.Tooltip('Probability', format='.4%')]
)
lines_1 = base_chart_1.mark_line()

# åˆ›å»ºè½¬æŠ˜ç‚¹çš„æ•°æ®
tp_data_1 = [{'K (Starters)': v, 'label': f'TP @ {v}'} for v in turning_points_1.values()]
if tp_data_1:
    tp_df_1 = pd.DataFrame(tp_data_1)
    rules_1 = alt.Chart(tp_df_1).mark_rule(color='red', strokeDash=[5,5], size=2).encode(x='K (Starters):Q')
    st.altair_chart((lines_1 + rules_1).interactive(), use_container_width=True)
else:
    st.altair_chart(lines_1.interactive(), use_container_width=True)

# --- æ–°å¢: è¾¹é™…æ•ˆç›Šåˆ†æ ---
st.write("ğŸ“ˆ **è¾¹é™…æ•ˆç›Šåˆ†æ (Marginal Utility Analysis):**")
st.write("ä¸Šå›¾ä¸­çº¢è‰²è™šçº¿æ ‡ç¤ºå‡ºäº†æ¯æ¡æ›²çº¿ä¸Šè¾¹é™…æ•ˆç›Šæœ€é«˜ç‚¹ (The point of maximum marginal gain)ã€‚è¿™ä»£è¡¨åœ¨è¯¥ç‚¹ï¼ˆKå€¼ï¼‰å¢åŠ ä¸€å¼ åŠ¨ç‚¹å¸¦æ¥çš„æ¦‚ç‡æå‡æ˜¯æœ€å¤§çš„ã€‚è¶…è¿‡è¿™ä¸ªç‚¹åï¼Œæ¯å†å¢åŠ ä¸€å¼ åŠ¨ç‚¹ï¼Œå…¶å¸¦æ¥çš„æ¦‚ç‡æå‡å°†å¼€å§‹å‡å°‘ï¼ˆæ”¶ç›Šé€’å‡ï¼‰ã€‚å„æ›²çº¿çš„è½¬æŠ˜ç‚¹å¦‚ä¸‹ï¼š")
if turning_points_1:
    tp_cols_1 = st.columns(len(turning_points_1))
    i = 0
    for curve, k_val in turning_points_1.items():
        with tp_cols_1[i]:
            st.metric(label=f"è½¬æŠ˜ç‚¹: {curve.split('/')[0].strip()}", value=f"K = {k_val}")
        i += 1
# --- è¾¹é™…æ•ˆç›Šåˆ†æç»“æŸ ---

if K_HIGHLIGHT in df_plot_1.index:
    # ... (rest of Part 1 remains the same)
    highlight_data_1 = df_plot_1.loc[K_HIGHLIGHT]
    st.write(f"**Probabilities for K = {K_HIGHLIGHT} / K = {K_HIGHLIGHT} æ—¶çš„æ¦‚ç‡:**")
    valid_cols_1 = [col for col in highlight_data_1.index if not pd.isna(highlight_data_1[col])]
    cols_1 = st.columns(len(valid_cols_1))
    col_idx_1 = 0
    for col_name, prob in highlight_data_1.items():
        if not pd.isna(prob): 
            with cols_1[col_idx_1]:
                st.metric(label=col_name.split('/')[0].strip(), value=f"{prob:.2%}") 
                col_idx_1 += 1
else:
    st.caption(f"Value for K={K_HIGHLIGHT} not available in this chart (max K is {DECK_SIZE}).")
st.header(f"ğŸ“Š Probability Tables (K=1 to {DECK_SIZE}) / æ¦‚ç‡è¡¨") 
for (table_name, table_data) in all_tables_1:
    with st.expander(f"**{table_name}**"): st.dataframe(table_data, use_container_width=True)


# =================================================================================
# Part 2
# =================================================================================
st.divider()
st.header("Part 2: P(At least 1 Starter AND At least 1 'Insecticide') / Part 2: P(è‡³å°‘1åŠ¨ç‚¹ ä¸” è‡³å°‘1æ€è™«å‰‚)")
st.write(f"This chart uses the Fixed Starter (K) count of **{STARTER_COUNT_K}** and shows how the probability changes as the 'Insecticide' (A) count (the X-axis) increases in your opening hand (n cards). / æ­¤å›¾è¡¨ä½¿ç”¨å›ºå®šçš„åŠ¨ç‚¹æ•° K=**{STARTER_COUNT_K}**ï¼Œæ˜¾ç¤ºéšç€å¡ç»„ä¸­â€˜æ€è™«å‰‚â€™(A) æ•°é‡ (Xè½´) çš„å¢åŠ ï¼Œèµ·æ‰‹æ‰‹ç‰Œ (nå¼ ) ä¸­åŒæ—¶æŠ½åˆ°è‡³å°‘1åŠ¨ç‚¹å’Œè‡³å°‘1æ€è™«å‰‚çš„æ¦‚ç‡å˜åŒ–ã€‚")
st.caption("Assumption: This calculation assumes 'Starters' (K) and 'Insecticides' (A) are separate, non-overlapping sets of cards. / æ³¨ï¼šæ­¤è®¡ç®—å‡è®¾åŠ¨ç‚¹ (K) å’Œæ€è™«å‰‚ (A) æ˜¯å®Œå…¨ä¸é‡å çš„ä¸¤ç»„å¡ã€‚")

if STARTER_COUNT_K >= DECK_SIZE:
    st.error(f"Error: Fixed Starter Count (K={STARTER_COUNT_K}) must be less than Total Deck Size (D={DECK_SIZE}).")
else:
    max_A_part2 = DECK_SIZE - STARTER_COUNT_K
    if max_A_part2 < 0:
         st.warning("Warning: K is larger than Deck Size.")
    else:
        st.subheader("Probability Formula / æ¦‚ç‡å…¬å¼")
        st.latex(r"P(\text{...}) = 1 - \frac{\binom{D-A}{n} + \binom{D-K}{n} - \binom{D-K-A}{n}}{\binom{D}{n}}")
        
        df_plot_2, df_table_2, turning_point_2 = get_combo_probability_data(DECK_SIZE, HAND_SIZE, STARTER_COUNT_K)
        
        # --- ä¿®æ”¹: ä½¿ç”¨ Altair ç»˜åˆ¶å›¾è¡¨ ---
        base_chart_2 = alt.Chart(df_plot_2.reset_index()).encode(
            x=alt.X('A (Insecticides):Q', title='A (Number of Insecticides in Deck)'),
            y=alt.Y('Probability:Q', axis=alt.Axis(format='%'), title='Probability'),
            tooltip=['A (Insecticides)', alt.Tooltip('Probability', format='.4%')]
        )
        lines_2 = base_chart_2.mark_line()
        if turning_point_2 is not None:
            tp_df_2 = pd.DataFrame([{'A (Insecticides)': turning_point_2}])
            rule_2 = alt.Chart(tp_df_2).mark_rule(color='red', strokeDash=[5,5], size=2).encode(x='A (Insecticides):Q')
            st.altair_chart((lines_2 + rule_2).interactive(), use_container_width=True)
        else:
            st.altair_chart(lines_2.interactive(), use_container_width=True)
        
        # --- æ–°å¢: è¾¹é™…æ•ˆç›Šåˆ†æ ---
        st.write("ğŸ“ˆ **è¾¹é™…æ•ˆç›Šåˆ†æ (Marginal Utility Analysis):**")
        if turning_point_2 is not None:
            st.write(f"ä¸Šå›¾ä¸­çº¢è‰²è™šçº¿ï¼ˆA = {turning_point_2}ï¼‰æ ‡ç¤ºå‡ºè¾¹é™…æ•ˆç›Šæœ€é«˜ç‚¹ã€‚åœ¨æ­¤ä¹‹åï¼Œæ¯å¢åŠ ä¸€å¼ 'æ€è™«å‰‚'å¸¦æ¥çš„æ¦‚ç‡æå‡å°†å¼€å§‹å‡å°‘ã€‚")
        else:
            st.write("æœªæ‰¾åˆ°æ˜æ˜¾çš„æ”¶ç›Šé€’å‡è½¬æŠ˜ç‚¹ã€‚")

        # ... (rest of Part 2 remains the same)
        st.header(f"ğŸ“Š Probability Table (A=0 to {max_A_part2}) / æ¦‚ç‡è¡¨")
        df_display_2 = df_table_2.copy()
        df_display_2["Probability / æ¦‚ç‡"] = df_display_2["Probability / æ¦‚ç‡"].map('{:.4%}'.format)
        df_display_2["P(A+1) - P(A) (Marginal / è¾¹é™…)"] = df_display_2["P(A+1) - P(A) (Marginal / è¾¹é™…)"].map('{:+.4%}'.format)
        df_display_2["P(A+1)-2P(A)+P(A-1) (Curvature / æ›²ç‡)"] = df_display_2["P(A+1)-2P(A)+P(A-1) (Curvature / æ›²ç‡)"].map('{:+.4%}'.format)
        st.dataframe(df_display_2, use_container_width=True, height=300)


# =================================================================================
# Part 3, Chart 1
# =================================================================================
st.divider()
st.header("Part 3, Chart 1: P(Draw `i` Non-Engine in 5 AND >= 1 Starter in 6) / Part 3, å›¾1: P(æŠ½5å¼ å«iå¼ ç³»ç»Ÿå¤– ä¸” æŠ½6å¼ å«>=1åŠ¨ç‚¹)")
st.write(f"This chart uses the Fixed Starter (K) count of **{STARTER_COUNT_K}**. The X-axis is the **Non-Engine (NE) count**. / æ­¤å›¾è¡¨ä½¿ç”¨å›ºå®šçš„åŠ¨ç‚¹æ•° K=**{STARTER_COUNT_K}**ã€‚Xè½´æ˜¯å¡ç»„ä¸­ç³»ç»Ÿå¤–å¡ç‰Œ (NE) çš„æ•°é‡ã€‚")

if STARTER_COUNT_K >= DECK_SIZE:
    st.error(f"Error: Fixed Starter Count (K={STARTER_COUNT_K}) must be less than Total Deck Size (D={DECK_SIZE}).")
elif max_ne_possible < 0:
     st.warning(f"Warning: K ({STARTER_COUNT_K}) + Highlighted NE ({NE_HIGHLIGHT}) cannot exceed Deck Size ({DECK_SIZE}).")
else:
    max_NE = max_ne_possible
    df_plot_3, all_tables_3, turning_points_3 = get_part3_data(DECK_SIZE, STARTER_COUNT_K)
    
    # --- ä¿®æ”¹: ä½¿ç”¨ Altair ç»˜åˆ¶å›¾è¡¨ ---
    df_plot_3_melted = df_plot_3.reset_index().melt('NE (Non-Engine)', var_name='Curve', value_name='Probability')
    base_chart_3 = alt.Chart(df_plot_3_melted).encode(
        x=alt.X('NE (Non-Engine):Q', title='NE (Number of Non-Engine cards in Deck)'),
        y=alt.Y('Probability:Q', axis=alt.Axis(format='%'), title='Probability'),
        color='Curve:N',
        tooltip=['NE (Non-Engine)', 'Curve', alt.Tooltip('Probability', format='.4%')]
    )
    lines_3 = base_chart_3.mark_line()
    tp_data_3 = [{'NE (Non-Engine)': v} for v in turning_points_3.values()]
    if tp_data_3:
        tp_df_3 = pd.DataFrame(tp_data_3)
        rules_3 = alt.Chart(tp_df_3).mark_rule(color='red', strokeDash=[5,5], size=2).encode(x='NE (Non-Engine):Q')
        st.altair_chart((lines_3 + rules_3).interactive(), use_container_width=True)
    else:
        st.altair_chart(lines_3.interactive(), use_container_width=True)

    # --- æ–°å¢: è¾¹é™…æ•ˆç›Šåˆ†æ ---
    st.write("ğŸ“ˆ **è¾¹é™…æ•ˆç›Šåˆ†æ (Marginal Utility Analysis):**")
    st.write("çº¢è‰²è™šçº¿æ ‡ç¤ºäº†æ¯æ¡æ›²çº¿æ”¶ç›Šé€’å‡çš„è½¬æŠ˜ç‚¹ã€‚å„æ›²çº¿è½¬æŠ˜ç‚¹å¦‚ä¸‹ï¼š")
    if turning_points_3:
        tp_cols_3 = st.columns(min(len(turning_points_3), 5)) # Avoid too many columns
        i = 0
        for curve, ne_val in turning_points_3.items():
            with tp_cols_3[i % 5]:
                st.metric(label=f"è½¬æŠ˜ç‚¹: {curve.split('/')[0].strip()}", value=f"NE = {ne_val}")
            i += 1
    
    # ... (rest of Part 3, Chart 1 remains the same)
    if NE_HIGHLIGHT in df_plot_3.index:
        highlight_data = df_plot_3.loc[NE_HIGHLIGHT]
        st.write(f"**Probabilities for NE = {NE_HIGHLIGHT} / NE = {NE_HIGHLIGHT} æ—¶çš„æ¦‚ç‡:**")
        cols = st.columns(len(highlight_data))
        for idx, (col_name, prob) in enumerate(highlight_data.items()):
            if not pd.isna(prob): 
                 with cols[idx]:
                    st.metric(label=col_name.split('(')[0].strip(), value=f"{prob:.2%}") 
    st.header(f"ğŸ“Š Probability Tables (X-axis = NE, from 0 to {max_NE}) / æ¦‚ç‡è¡¨")
    for (table_name, table_data) in all_tables_3:
        with st.expander(f"**{table_name}**"): st.dataframe(table_data, use_container_width=True)

# =================================================================================
# Part 3, Chart 2
# =================================================================================
st.divider()
st.header("Part 3, Chart 2: P(Draw `>= i` Non-Engine in 5 AND >= 1 Starter in 6) / Part 3, å›¾2: P(æŠ½5å¼ å«>=iå¼ ç³»ç»Ÿå¤– ä¸” æŠ½6å¼ å«>=1åŠ¨ç‚¹)")
st.write(f"This chart shows the cumulative probability. It uses the Fixed Starter (K) count of **{STARTER_COUNT_K}**. The X-axis is the **Non-Engine (NE) count**. / æ­¤å›¾è¡¨æ˜¾ç¤ºç´¯ç§¯æ¦‚ç‡ã€‚ä½¿ç”¨å›ºå®šçš„åŠ¨ç‚¹æ•° K=**{STARTER_COUNT_K}**ã€‚Xè½´æ˜¯å¡ç»„ä¸­ç³»ç»Ÿå¤–å¡ç‰Œ (NE) çš„æ•°é‡ã€‚")

if STARTER_COUNT_K < DECK_SIZE and max_ne_possible >= 0:
    max_NE_2 = max_ne_possible
    df_plot_3_cumulative, all_tables_3_cumulative, turning_points_3c = get_part3_cumulative_data(DECK_SIZE, STARTER_COUNT_K)
    
    # --- ä¿®æ”¹: ä½¿ç”¨ Altair ç»˜åˆ¶å›¾è¡¨ ---
    df_plot_3c_melted = df_plot_3_cumulative.reset_index().melt('NE (Non-Engine)', var_name='Curve', value_name='Probability')
    base_chart_3c = alt.Chart(df_plot_3c_melted).encode(
        x=alt.X('NE (Non-Engine):Q', title='NE (Number of Non-Engine cards in Deck)'),
        y=alt.Y('Probability:Q', axis=alt.Axis(format='%'), title='Cumulative Probability'),
        color='Curve:N',
        tooltip=['NE (Non-Engine)', 'Curve', alt.Tooltip('Probability', format='.4%')]
    )
    lines_3c = base_chart_3c.mark_line()
    tp_data_3c = [{'NE (Non-Engine)': v} for v in turning_points_3c.values()]
    if tp_data_3c:
        tp_df_3c = pd.DataFrame(tp_data_3c)
        rules_3c = alt.Chart(tp_df_3c).mark_rule(color='red', strokeDash=[5,5], size=2).encode(x='NE (Non-Engine):Q')
        st.altair_chart((lines_3c + rules_3c).interactive(), use_container_width=True)
    else:
        st.altair_chart(lines_3c.interactive(), use_container_width=True)

    # --- æ–°å¢: è¾¹é™…æ•ˆç›Šåˆ†æ ---
    st.write("ğŸ“ˆ **è¾¹é™…æ•ˆç›Šåˆ†æ (Marginal Utility Analysis):**")
    st.write("çº¢è‰²è™šçº¿æ ‡ç¤ºäº†æ¯æ¡æ›²çº¿æ”¶ç›Šé€’å‡çš„è½¬æŠ˜ç‚¹ã€‚å„æ›²çº¿è½¬æŠ˜ç‚¹å¦‚ä¸‹ï¼š")
    if turning_points_3c:
        tp_cols_3c = st.columns(len(turning_points_3c))
        i = 0
        for curve, ne_val in turning_points_3c.items():
            with tp_cols_3c[i]:
                st.metric(label=f"è½¬æŠ˜ç‚¹: {curve.split('(')[0].strip()}", value=f"NE = {ne_val}")
            i += 1
    
    # ... (rest of Part 3, Chart 2 remains the same)
    if NE_HIGHLIGHT in df_plot_3_cumulative.index:
        highlight_data_cumul = df_plot_3_cumulative.loc[NE_HIGHLIGHT]
        st.write(f"**Cumulative Probabilities for NE = {NE_HIGHLIGHT} / NE = {NE_HIGHLIGHT} æ—¶çš„ç´¯ç§¯æ¦‚ç‡:**")
        cols_cumul = st.columns(len(highlight_data_cumul))
        for idx, (col_name, prob) in enumerate(highlight_data_cumul.items()):
            if not pd.isna(prob):
                 with cols_cumul[idx]:
                    st.metric(label=col_name.split('(')[0].strip(), value=f"{prob:.2%}") 
    st.header(f"ğŸ“Š Cumulative Probability Tables (X-axis = NE, from 0 to {max_NE_2}) / ç´¯ç§¯æ¦‚ç‡è¡¨")
    for (table_name, table_data) in all_tables_3_cumulative:
        with st.expander(f"**{table_name}**"): st.dataframe(table_data, use_container_width=True)

# =================================================================================
# Part 4
# =================================================================================
st.divider()
st.header("Part 4: P(Draw `i` Non-Engine AND `6-i` Starters in 6 cards) / Part 4: P(æŠ½6å¼ å«iå¼ ç³»ç»Ÿå¤– ä¸” 6-iå¼ åŠ¨ç‚¹)")
st.write(f"This chart analyzes the exact hand composition after drawing 6 cards (going second). It uses the Fixed Starter (K) count of **{STARTER_COUNT_K}**. The X-axis is the **Non-Engine (NE) count**. / æ­¤å›¾è¡¨åˆ†æåæ”»æŠ½å®Œ6å¼ ç‰Œåçš„ç²¾ç¡®æ‰‹ç‰Œæ„æˆã€‚ä½¿ç”¨å›ºå®šçš„åŠ¨ç‚¹æ•° K=**{STARTER_COUNT_K}**ã€‚Xè½´æ˜¯å¡ç»„ä¸­ç³»ç»Ÿå¤–å¡ç‰Œ (NE) çš„æ•°é‡ã€‚")

if STARTER_COUNT_K < DECK_SIZE and max_ne_possible >= 0:
    max_NE_4 = max_ne_possible
    df_plot_4, all_tables_4, turning_points_4 = get_part4_data(DECK_SIZE, STARTER_COUNT_K)
    
    # --- ä¿®æ”¹: ä½¿ç”¨ Altair ç»˜åˆ¶å›¾è¡¨ ---
    df_plot_4_melted = df_plot_4.reset_index().melt('NE (Non-Engine)', var_name='Curve', value_name='Probability')
    base_chart_4 = alt.Chart(df_plot_4_melted).encode(
        x=alt.X('NE (Non-Engine):Q', title='NE (Number of Non-Engine cards in Deck)'),
        y=alt.Y('Probability:Q', axis=alt.Axis(format='%'), title='Probability'),
        color='Curve:N',
        tooltip=['NE (Non-Engine)', 'Curve', alt.Tooltip('Probability', format='.4%')]
    )
    lines_4 = base_chart_4.mark_line()
    tp_data_4 = [{'NE (Non-Engine)': v} for v in turning_points_4.values()]
    if tp_data_4:
        tp_df_4 = pd.DataFrame(tp_data_4)
        rules_4 = alt.Chart(tp_df_4).mark_rule(color='red', strokeDash=[5,5], size=2).encode(x='NE (Non-Engine):Q')
        st.altair_chart((lines_4 + rules_4).interactive(), use_container_width=True)
    else:
        st.altair_chart(lines_4.interactive(), use_container_width=True)

    # --- æ–°å¢: è¾¹é™…æ•ˆç›Šåˆ†æ ---
    st.write("ğŸ“ˆ **è¾¹é™…æ•ˆç›Šåˆ†æ (Marginal Utility Analysis):**")
    st.write("çº¢è‰²è™šçº¿æ ‡ç¤ºäº†æ¯æ¡æ›²çº¿æ”¶ç›Šé€’å‡çš„è½¬æŠ˜ç‚¹ã€‚å„æ›²çº¿è½¬æŠ˜ç‚¹å¦‚ä¸‹ï¼š")
    if turning_points_4:
        tp_cols_4 = st.columns(min(len(turning_points_4), 5))
        i = 0
        for curve, ne_val in turning_points_4.items():
            with tp_cols_4[i % 5]:
                st.metric(label=f"è½¬æŠ˜ç‚¹: {curve.split('(')[0].strip()}", value=f"NE = {ne_val}")
            i += 1
            
    # ... (rest of Part 4 remains the same)
    if NE_HIGHLIGHT in df_plot_4.index:
        highlight_data_4 = df_plot_4.loc[NE_HIGHLIGHT]
        st.write(f"**Exact Hand Probabilities for NE = {NE_HIGHLIGHT} / NE = {NE_HIGHLIGHT} æ—¶çš„ç²¾ç¡®æ‰‹ç‰Œæ¦‚ç‡:**")
        cols_4 = st.columns(len(highlight_data_4))
        for idx, (col_name, prob) in enumerate(highlight_data_4.items()):
            if not pd.isna(prob):
                with cols_4[idx]:
                    st.metric(label=col_name.split('(')[0].strip(), value=f"{prob:.2%}") 
    st.header(f"ğŸ“Š Probability Tables (X-axis = NE, from 0 to {max_NE_4}) / æ¦‚ç‡è¡¨")
    for (table_name, table_data) in all_tables_4:
        with st.expander(f"**{table_name}**"): st.dataframe(table_data, use_container_width=True)


# --- Footer ---


st.divider()
st.caption("Note: Don't dive it. Cuz the data is just for reference only. / æ³¨ï¼šè¯·å‹¿è¿‡åº¦æ‰§ç€è®¡ç®—ï¼Œæ•°æ®ä»…ä¾›å‚è€ƒã€‚") 

try:
    img_meme = Image.open("meme.png") 
    target_width_meme = 300 
    
    w_percent_meme = (target_width_meme / float(img_meme.size[0]))
    target_height_meme = int((float(img_meme.size[1]) * float(w_percent_meme)))
    
    img_meme_resized = img_meme.resize((target_width_meme, target_height_meme), Image.Resampling.LANCZOS)
    
    st.image(img_meme_resized) 
except FileNotFoundError:
    st.caption("meme.png not found. (Place it in the same folder as the script)")
except Exception as e:
    st.error(f"Error loading meme image: {e}")
